{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Melasma Skin Disease Diagnosis Using Deep Neural Networks\n",
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NqSrw5E4DgB3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from src.dataloader import *\n",
        "from src.models import *\n",
        "from src.train import train\n",
        "from src.evaluate import test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part1: pre-train on CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "O5zwihlLDgB5"
      },
      "outputs": [],
      "source": [
        "# Variables\n",
        "data_dir = \"./data/CIFAR10\"\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "num_channels = 3\n",
        "num_epochs = 100\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAv8AT6DDgB5",
        "outputId": "676aacef-add0-499a-841a-c686a5714546"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Dataset Successfully loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load Pre-Train Dataset (CIFAR10)\n",
        "train_loader, test_loader = cifar10_loader(data_dir, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvt4tLjWDgB8"
      },
      "source": [
        "### VGGNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qndv6hpjDgB9",
        "outputId": "201fc5ca-4294-4800-a27d-eac771324ef6"
      },
      "outputs": [],
      "source": [
        "vggnet_model = VGGNet16(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vggnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vggnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(vggnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(vggnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/CIFAR10-VGGNet16-TRAINHISTORY.json\")\n",
        "torch.save(vggnet_model,\"./models/CIFAR10-VGGNet16-CHECKPOINTS.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj6o9cJODgB-"
      },
      "source": [
        "### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4VSTDuODgB_",
        "outputId": "367143d9-4386-4068-a580-92c95feb89ef"
      },
      "outputs": [],
      "source": [
        "resnet_model = ResNet(Bottleneck, [3,4,6,3], num_classes=num_classes , num_channels=num_channels).to(device) # ResNet50 --> 3,4,6,3\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(resnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(resnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/CIFAR10-ResNet50-TRAINHISTORY.json\")\n",
        "torch.save(resnet_model,\"./models/CIFAR10-ResNet50-CHECKPOINTS.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG-opTG5DgB_"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvVO6oUzDgCA",
        "outputId": "c64d8b28-b66a-4d0d-d1c6-089c25bd08ca"
      },
      "outputs": [],
      "source": [
        "alexnet_model = AlexNet(num_classes=num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(alexnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(alexnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(alexnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/CIFAR10-AlexNet-TRAINHISTORY.json\")\n",
        "torch.save(alexnet_model,\"./models/CIFAR10-AlexNet-CHECKPOINTS.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2: train on Melesema Skin Disease Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Variables\n",
        "data_dir = \"./data/MelesemaImages\"\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "num_channels = 3\n",
        "num_epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tITfpVzYO5eJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Batch of images shape: torch.Size([32, 3, 224, 224])\n",
            "Train Batch of labels: tensor([0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
            "        1, 1, 0, 1, 0, 1, 0, 0])\n",
            "Test Batch of images shape: torch.Size([24, 3, 224, 224])\n",
            "Test Batch of labels: tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "# Load Train Dataset (Melasema)\n",
        "train_loader, test_loader = melasema_loader(data_dir, batch_size)\n",
        "\n",
        "train_images, train_labels = next(iter(train_loader))\n",
        "print(f'Train Batch of images shape: {train_images.shape}')\n",
        "print(f'Train Batch of labels: {train_labels}')\n",
        "\n",
        "test_images, test_labels = next(iter(test_loader))\n",
        "print(f'Test Batch of images shape: {test_images.shape}')\n",
        "print(f'Test Batch of labels: {test_labels}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vggnet_model = torch.load(\".models/CIFAR10-VGGNet16-CHECKPOINTS.pth\", weights_only=False)\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(vggnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vggnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(vggnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(vggnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/Melasema-VGGNet16-TRAINHISTORY.json\")\n",
        "torch.save(vggnet_model,\"./models/Melasema-VGGNet16-CHECKPOINTS.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet_model = torch.load(\"CIFAR10-ResNet50-CHECKPOINTS.pth\", weights_only=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "for epoch in range(num_epochs):\n",
        "    resnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(resnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(resnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/Melasema-ResNet50-TRAINHISTORY.json\")\n",
        "torch.save(resnet_model,\"./models/Melasema-ResNet50-CHECKPOINTS.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alexnet_model = torch.load(\"CIFAR10-AlexNet-CHECKPOINTS.pth\", weights_only=False)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(alexnet_model.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "history = []\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet_model.train(True)\n",
        "    train_loss, train_accuracy = train(alexnet_model, train_loader, criterion, optimizer)\n",
        "    test_loss, test_accuracy = test(alexnet_model, test_loader, criterion)\n",
        "\n",
        "    data = {\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\": train_accuracy,\n",
        "        \"Test Loss\": test_loss,\n",
        "        \"Test Accuracy\": test_accuracy,\n",
        "    }\n",
        "    print(data)\n",
        "    history.append(data)\n",
        "\n",
        "pd.DataFrame(history).to_json(\"./history/Melasema-AlexNet-TRAINHISTORY.json\")\n",
        "torch.save(alexnet_model,\"./models/Melasema-AlexNet-CHECKPOINTS.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
